<!DOCTYPE html>
<html lang="en-US"><head>
		<meta charset="UTF-8">
		<title>FT944-6973</title>
	</head>
	<body>
		<main>
			<p>941126 FT  26 NOV 94 / New conclusions from old studies: The Nature of Things You are an ambitious medical researcher working on a controversial issue - say, the effect of diet on cancer or heart disease. Several clinical trials have been published, giving contradictory results. How can you make the biggest impact in the field? The traditional way would be to raise millions of pounds worth of research grants to carry out the definitive study, with a better procedure and more participants than any previous trial. An alternative approach is to gather all your predecessors' work and re-analyse their results, using a powerful statistical technique known as meta-analysis. This could lead to a clear conclusion much more quickly and at far lower cost than organising a new study. The foundations of meta-analysis were laid in the 1970s by epidemiologists such as Richard Peto in the UK and Thomas Chalmers in the US. They were looking for a path through the confusing thicket of data thrown up by the proliferation of clinical trials. Meta-analysis involves combining the results of separate studies carried out to answer the same question - for example, does eating garlic reduce the risk of a heart attack? The reason for pooling data is to iron out the chance fluctuations which can obscure the significance of individual studies. The conventional target for achieving 'statistical significance' is a probability of more than 95 per cent that a result was achieved through the drug or activity being studied, rather than by chance. If the effect is real though fairly small, it may not show up in 20 studies with 300 people but it should give a statistically significant outcome in a combined analysis of 6,000 people. A systematic review of all clinical data, including meta-analysis, is quite different to the informal reviews traditionally published in the medical literature. These often miss important conclusions by looking at the evidence as a collection of individual studies and dismissing the ones that do not have a statistically significant outcome. Meta-analysis made its first big impact in 1985 when Richard Peto and Rory Collins of the ICRF Clinical Trials Unit in Oxford transformed the treatment of breast cancer by showing that a drug called tamoxifen improved five-year survival rates. In the cardiovascular field, it was not until 1988 that the medical profession recognised the ability of thrombolytic 'clot-busting' drugs such as streptokinase to save the lives of heart attack patients. By then, 70 separate clinical trials had been carried out on a total of 47,000 patients. Yet statisticians now calculate that there had been enough clinical evidence to prove the effectiveness of streptokinase as early as 1973, when 10 trials had taken place with 2,500 patients - if only someone had done the meta-analysis. The introduction of routine thrombolytic therapy then, rather than 15 years later, would have saved more than half a million lives worldwide. It would be wrong, however, to give the impression that meta-analysis is an easy option. The first essential is to draw up clear objectives for the review, with criteria for including or excluding studies. Then you have to track down the data, which may be the hardest job of all. Despite the spread of computerised databases, conducting a worldwide search for all published studies is an enormous task; there are an estimated 20,000 medical journals worldwide, many in foreign languages. But serious reviewers must also search for unpublished studies. Otherwise the meta-analysis may suffer from 'publication bias' - the tendency for researchers and journals to publish studies with a positive outcome, in preference to those that are inconclusive or negative. Deciding which studies to include or exclude is fairly straightforward when the meta-analyst is looking at the effect of drugs. Then he or she can restrict the field to 'randomised controlled trials' in which the subjects are divided at random into two groups; one takes the drug and the other a placebo, and ideally neither the patients nor the researchers know which is which. For 'observational studies', examining for example the impact of diet, smoking or environmental factors on health, the eligibility criteria become harder to define and implement. And when meta-analysis moves away from health to the social sciences, there is great scope for ambiguity and confusion. Social scientists are turning to meta-analysis as a way of settling issues ranging from the impact of pre-school education on later academic achievement to the effect of job training on unemployment. But its use here is still controversial. Some argue that individual studies are too dissimilar in methodology and quality for the results to be pooled. Most health researchers, however, have embraced meta-analysis as a powerful new tool for fishing original conclusions out of old data. At the same time, they point out that meta-analysis does not remove the need to refresh the pool with well-designed new studies, such as the big Scandinavian trial of cholesterol-lowering drugs published last week. Medical progress will require a co-ordinated combination of the two approaches.</p>
		</main>
</body></html>
            