<!DOCTYPE html>
<html lang="en-US"><head>
		<meta charset="UTF-8">
		<title>FT932-12215</title>
	</head>
	<body>
		<main>
			<p>930429 FT  29 APR 93 / Personal View: Hidden flaws in school testing 'National testing is a vital element of our drive for higher standards in schools,' proclaims the schools minister, Eric Forth. Yet it is obvious that testing itself does nothing to raise standards. It is like taking a person's temperature. A test simply tells you something about the condition of the pupil. The single aim of testing of any kind is to produce information. It is the quality of the information and how it is used that determine whether standards go up or down or change not at all. A high temperature tells a doctor something is wrong, not what is wrong. For that, other tests may be needed. By analogy, there are different kinds of school tests, designed to reveal different things. The 1987 report of the Task Group on Assessment and Training, chaired by Professor Paul Black, listed four purposes of testing: Formative, for deciding 'appropriate next steps' in a pupil's study. Diagnostic, to identify 'learning difficulties'. Summative, recording what a pupil has learnt. Evaluative, to compare one school with others. The TGAT report took two crucial decisions. The first was that it would be impracticable to have different tests for different purposes. Secondly, it argued that while it was possible to use formative/ diagnostic tests for summative/ evaluative purposes, the reverse was not true. Tests designed to record what had been learnt over a given period could not, by definition, show what needed to be done to improve learning in that period. The main conclusion the report drew was that the purpose of assessment should be formative/ diagnostic. However, the assessments could also be used to make summative judgments on individual pupils, and evaluate the performance of schools over the same period, if a common basis of progression in relation to national targets could be worked out. But these additional tasks were strictly subordinate to the main purpose, which was to help teachers improve the learning of individual pupils. These conclusions of the TGAT report are the source of the present trouble over testing in schools. The report barely concealed its hostility to using national assessment to 'evaluate the work of the education service'. But the government's strategy for raising educational standards was to do just that. The report enshrined the principle of teacher-controlled continuous assessment which is at odds with the notion of end-of-key-stage testing of seven-, 11- and 14-year-olds. Since the government was eager to get the principle of regular testing established, it fudged this uncomfortable philosophic divide in accepting the TGAT proposals. The fact is that tests which explicitly aim to help learning will be different from tests which aim to measure the results of teaching - it is doubtful whether even the same word should be used for the two. This became clear in 1991 when the first so-called tests for seven-year-olds in English, arithmetic and science arrived in the schools. They required dozens of 'standard assessment tasks' which took half a term to administer, and came with recording instructions of Byzantine complexity. Since then, end-of-key-stage tests have been slimmed down to improve 'manageability'. But the more manageable - that is, shorter - the tests become, the more unlike teacher assessment they look. The simmering dispute has come to the boil with the national curriculum English tests for 14-year-olds to be taken this summer. Teachers have attacked poor timing, poor quality and increased workload. But the gut issues have also emerged clearly. Who controls the tests? What are they for? No review of the 'manageability' of national assessment can duck these questions. The logical solution would be to separate teacher assessment from end-of-stage tests, which should be externally set and marked, possibly by a consortium of test boards. This would reverse the key decision of the TGAT report not to have different tests for different purposes. Teachers' workload as well as the time pupils would have to spend on the tests would be reduced. But the reform would also disclose the real ground of teachers' complaint: the use of tests that they do not control to pass judgments on their performance. Accountability requires information. The information required to judge schools cannot be controlled by the schools. If the boycott of this summer's tests brings greater understanding of this single point, then it will have done some good. The author is a member of the School Examinations and Assessment Council</p>
		</main>
</body></html>
            