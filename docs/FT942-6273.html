<!DOCTYPE html>
<html lang="en-US"><head>
		<meta charset="UTF-8">
		<title>FT942-6273</title>
	</head>
	<body>
		<main>
			<p>940531 FT  31 MAY 94 / Survey of the Computer Industry - Battle for the Desktop (9): Better access to data / New ways to link 'islands of information' The spread of desktop personal computers poses a special problem for database developers: how can they bring the so-called 'islands of information' together to form a coherent data resource and make it work for the business? It is probably an exaggeration to say that every piece of data on every personal computer (PC), every departmental computer and the central corporate mainframe is valuable. But there is no doubt that important data sits on all of these computers and, for it to be of benefit to the business, there must be a way to get at it and make it available for all those who need it. The proliferation of data across the network is the inevitable result of distributing computer power to the desktop. As individuals get their hands on PCs, they create their own local data resources. And, as PCs have been plugged into corporate networks, users have been able to access data from other sources. Usually this data has come from central corporate systems. But increasingly it is being distributed to departmental database 'servers' and even to individual desktop PCs. This has become possible because of changes in the way that database software works. Over the last decade, database technology has fragmented into front-end tools to access and manipulate data and back-end server 'engines' which can store it in the most efficient way. The client-server approach to designing computer systems has its origins in this separation of data and the means to access it. Database software suppliers have concentrated their efforts on improving the performance of their server engines so that they can compete with the mainframe-based systems. But attention has shifted to the front-end tools; software suppliers have had to accommodate each others tools and engines to cope with user demand for data - 'a lot of corporate data is sitting on desktop PCs and companies want products that are flexible and can handle different database engines. They cannot realise their data assets without these tools,' says Mr Paul Hart, marketing manager at database supplier Unify. 'Standards have emerged in the database world and created a commodity market for tools and server engines - and, at the same time, the market has become more tool-orientated.' Standards such as Structured Query Language (SQL) and Open Database Connectivity (ODBC) provide the software 'glue' necessary to link the front end tools to the back end servers. This means, of course, that it is relatively simple to use a tool from one supplier to access data on a server from one or more different suppliers. Most database software suppliers must now offer tools which can link to the most popular 'engines' - such as Oracle, IBM's DB2, Ingres, Sybase and Informix - in addition to their own. 'We can supply a database server - but ours is one of many. You have to provide links using SQL to as many as twenty different servers,' says Mr Paul Salmon, UK marketing director at database specialist Gupta Technologies. Like its rivals, Gupta uses SQL and other standards to provide the links - 'we also support ODBC - although this does not necessarily give the performance you need for large-scale applications. ODBC is fine - but it is pretty basic and some customers have expressed concern over performance because it puts an extra layer of software between the tool and the server,' says Mr Salmon. Companies are expecting more from database technology on their local area networks (LANs) than before - 'companies want features such as security, record locking and recovery. This way they can be sure that their important corporate data is safe,' he adds. Other database suppliers have found that the pressure to put important applications on PC networks is putting pressure on database technology. 'There's a definite trend to put more serious applications on PC networks and this can lead customers into a position where they have data all over the place. They want the tools to bring it all together again,' says Mr Neil Morgan, desktop product marketing manager at Oracle in the UK. 'To the individual user who wants to combine information from different sources - it should appear as a single data resource,' he adds. 'We are building a set of transparent gateways to achieve this and let desktop PC users access data from anywhere on the network.' He points to the example of Rolls Royce: it has distributed its spare parts database for aero engines from its IBM mainframe DB2 database to an Oracle database running on a local server under the Unix operating system - 'there is a significant business benefit in doing this. It speeds up local access to the parts catalogue and improves customer service,' he explains. 'It also relieves the load on the central database server - an increasing problem since client-server networks came along. We're working on technology we call data staging which will make sure that the everything is kept in line when the data is distributed across the network.' A key part of distributing data in this way is to give users the desktop tools to access data and perform their own processing - rather than relying on complex applications software to do the job. The separation of these tools from the underlying database management software has opened up the software market - both for the database software suppliers and for others who concentrate solely on desktop tools. This has made the software market more competitive and gives users a wide range of choice.</p>
		</main>
</body></html>
            