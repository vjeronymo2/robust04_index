<!DOCTYPE html>
<html lang="en-US"><head>
		<meta charset="UTF-8">
		<title>FBIS3-42546</title>
	</head>
	<body>
		<main>
			<p>Language: <F P=105> Russian </F> Article Type:CSO   <F P=106> [Article by V. P. Kozlov, Yu. M. Timofeyev, A. V. Polyakov, </F> St. Petersburg State University; UDC 551.510.5]    [Abstract] Most satellite IR radiometers used for remote  sensing of the atmosphere and the underlying layer have systems  of onboard absolute calibration of measurements of outgoing  radiation. For various reasons, however, the instruments must be  calibrated independently for the different periods of their  operation. As a rule, such calibration consists of calculations  of the absolute values of the intensity of outgoing radiation on  the basis of the use of modern radiation models of the  atmosphere, information on the physical and optical state of the  atmosphere and the underlying layer in the areas of calibration,  and the spectral characteristics of the radiometers. There are  inherent difficulties in objectively assessing the accuracy of  such calibration and in factoring various kinds of information  into the calibration algorithms. The researchers here use the  statistical regression method in the calibration, guaranteeing  the smallest rms error of prediction and making it easy to  consider arbitrary sets of controlled variables and arbitrary  measurement modes. An adequate radiation model for statistical  modeling of emission variations is used for given variations of  parameters of an optical-meteorological model of the atmosphere.  The radiation model (an integral equation of thermal emission  transfer) is linearized in the vicinity of some standard  atmospheric state satisfying the average climatic or seasonal  conditions for a given region. References 7: 3 Russian, 4  Western.</p>
		</main>
</body></html>
            