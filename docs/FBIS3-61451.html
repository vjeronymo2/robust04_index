<!DOCTYPE html>
<html lang="en-US"><head>
		<meta charset="UTF-8">
		<title>FBIS3-61451</title>
	</head>
	<body>
		<main>
			<p>Language: <F P=105> Russian </F> Article Type:CSO   <F P=106> [Article by O.M. Brekhov, V.A. Moraru, Moscow Aviation </F> Engineering Institute; UDC 681.324:519.21]    [Abstract] A nontraditional dataflow computer architecture  whereby the sequence of tasks in the dataflow-controlled  computer (EVM UPD) is determined only by the readiness of the  relevant data and if resources permit, jobs are executed  concurrently and independently, is discussed, and an earlier  study is expanded. An evaluation of the dataflow computer  performance with changes in the multisequencing factor  K in the neighborhood of unity calls for developing a  probabilistic model with a random processor loading, i.e., given  commensurate data processing durations in the storage blocks and  processors. The dependence of the dataflow computer performance  on the types of jobs being executed is considered and compared  to the performance of a von Neumann series computer. An  efficient recurrent procedure is developed for determining the  steady-state dataflow computer model probabilities, making it  possible to assess the computer performance as a function of the  number of processors, storage blocks, their speed of response,  work load parameters, throughput, and communication networks. An  efficiency analysis demonstrates that as the number of  processors increases to ten or higher, the dataflow computer  performance is better than that of computer systems with  traditional architecture. The specific boundary depends on the  algorithmic and architectural parameters of the system under  study. Figures 14; references 8: 5 Russian, 3 Western.</p>
		</main>
</body></html>
            