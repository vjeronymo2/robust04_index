<!DOCTYPE html>
<html lang="en-US"><head>
		<meta charset="UTF-8">
		<title>FT943-1822</title>
	</head>
	<body>
		<main>
			<p>940922 FT  22 SEP 94 / Technology: Of machines and men - Vanessa Houlder launches a series on IT innovation in the financial services industry In the depths of Midland Global Market's blue glass offices by the River Thames, a phalanx of computers is engaged in a battle of man against machine. These systems, which have the collective power of a supercomputer, are attempting to find ways to beat the financial markets more consistently than human traders. Between five and 25 times a day, the basement's rarefied atmosphere is disturbed by a few bars of Deutschland uber Alles or the Star Spangled Banner. These tunes are emitted by a computer signalling a recommendation to buy or sell futures - the right or obligation to buy or sell a bond or other financial instrument at a certain date - in one of five markets: the bund (German bonds), FT-SE, US Treasury Bond, Swiss Franc or S&amp;P500. This is an example of a new phenomenon in the banking world. Midland's 16-month-old experiment with computer-based predictive models is one of numerous attempts in the City of London and Wall Street to find reliable ways of making money from advances in computing and mathematical theory. Over the past few years, the financial institutions have recruited mathematicians and physicists - known in the City as 'rocket scientists' - on an unprecedented scale. The Midland team, for example, includes two people who really are rocket scientists; the others have degrees and doctorates in physics, mathematics and engineering. Computerised trading models have aroused intense controversy. Their champions argue that 'intelligent' computer software will soon oust highly-paid traders; detractors argue that they are a pointless sideline, based on inherently flawed assumptions about the way that markets work. Some aspects of this debate are not new. Fascination with methods of predicting the market goes back centuries. For example, one system which gained popularity in the 1870s advised the investor to buy on the stock exchange when it had moved up by 10 per cent and sell when it had moved down by 10 per cent. The difficulty of manipulating data by hand put tight constraints on the number and complexity of trading rules that could be tested against the market. It was only when powerful computers and detailed historical market data became available that the creation of models could be pushed into a different league. The Midland system, for example, involves about 60 personal computers and a 16 gigabyte database, which holds up to 20 years of market data. It receives 250,000 prices daily, each of which is time-stamped with a radio signal from an atomic clock. But can computer models really predict the ways markets move? Classical economic theory suggests there is no systematic way to beat the market other than by receiving sensitive information faster. The markets are inherently unpredictable because they are only moved by unexpected news; old news is already assimilated in the market. This theory is seen by some as an over-simplification. Markets are driven by many different players, such as market makers, speculators, portfolio managers and central bankers. Since they have different investment horizons and different attitudes to risk, they may react to the same information in different ways. Many theorists believe that although most market movements are random, a sizeable proportion is not. Paul Refenes, head of non-linear applications and financial engineering at the London Business School, believes that sophisticated mathematical models based on non-linear dynamics are, in principle, capable of predicting 30 per cent of market movements. Although Nick Idelson, head of Midland's computer-based predictive models, is convinced that non-linear dynamics apply to the financial markets, his models are not based on any general theory. They have been derived by testing a large number of intuitive ideas about rules governing the markets. The models work by trying to make more money on successful trades than they lose on unsuccessful trades. One of the Midland models makes money despite getting the direction of the market wrong more often than it gets it right. In general, the six portfolios make less money than the firm's traders but they perform more consistently. Midland's S&amp;P500 models have beaten the S&amp;P500 index three-fold over two years. Their performance has by no means been faultless. For example, the model made significant losses in March and April - triggered, Idelson believes, by Japanese funds pulling large sums of money out of the bond markets. The model could not cope with this because the market conditions were unlike any encountered during testing. This highlights an important dilemma for model builders, namely deciding the exact circumstances when a trader should override the decisions made by the model. Some traders believe that automated trading machines should be switched off whenever market conditions differ from those in historical simulations. But ultimately, the decision about when to switch the machine on and off is a matter of subjective judgment. The problem of judging when the machine will be unable to cope with anomalous market conditions is made more acute by another possible explanation for a poor performance by a model, known as 'over-fitting' - when so many rules are incorporated in the model that it fits the historical data on which it was tested but is a dismal failure in live trading. This is a common pitfall for model builders who unwittingly take familiar data into account when designing their model or choosing their parameters. Another problem arises from changes in the pattern and behaviour of markets. Models should be periodically monitored to discover if there is a 'slow drift' in empirical parameters used to describe markets over time, according to Idelson. To some extent, it is inevitable that models may become obsolete. If enough people discover and exploit the same anomalies and patterns in the market, those anomalies and patterns will eventually disappear. 'It is a vicious circle,' says Refenes. 'The more tools there are, the more efficient the markets will become. Therefore they (traders) demand better tools and the market becomes still more efficient.' But this is seen as an opportunity, rather than a threat by Richard Olsen, who heads Olsen &amp; Associates, a Zurich-based research institute. He argues that the additional trading opportunities created by computer models will lead to higher market volumes, which will reduce transaction costs. This will increase opportunities for short-term trading, creating a more complex market and new opportunities for profitable trading models. To some, this vision of wealth-creating computers is an absurdity; others believe it is already within their grasp. Depending on which view is vindicated, the impact of new technology on the financial markets will either be a passing phenomenon, or will have profound, long-term effects. The next article in the series will focus on computing tools.</p>
		</main>
</body></html>
            